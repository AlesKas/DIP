{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_analytics = pd.read_csv('./data/Network_Analytics.csv')\n",
    "# series = pd.Series(network_analytics['OutboundUtilzation (%)'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of train_set : 80.00%\n",
      "Proportion of valid_set : 15.00%\n",
      "Proportion of test_set : 5.01%\n"
     ]
    }
   ],
   "source": [
    "train_len = int(len(network_analytics) * 0.80)\n",
    "valid_len = int(len(network_analytics) * 0.15)\n",
    "\n",
    "train = network_analytics[:train_len]\n",
    "valid = network_analytics[train_len:(train_len + valid_len)]\n",
    "test = network_analytics[train_len + len(valid):]\n",
    "\n",
    "assert len(network_analytics) == (len(train) + len(valid) + len(test))\n",
    "\n",
    "print('Proportion of train_set : {:.2f}%'.format(len(train)/len(network_analytics) * 100))\n",
    "print('Proportion of valid_set : {:.2f}%'.format(len(valid)/len(network_analytics) * 100))\n",
    "print('Proportion of test_set : {:.2f}%'.format(len(test)/len(network_analytics) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps):\n",
    "    x, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        \n",
    "        end_ix = i + n_steps\n",
    "        \n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(x, dtype=np.float32), np.array(y, dtype=np.float32)\n",
    "\n",
    "raw_seq = [10,20,30,40,50,60,70,80,90]\n",
    "n_steps = 3\n",
    "train_x,train_y = split_sequence(train['OutboundUtilzation (%)'].values,n_steps)\n",
    "valid_x,valid_y = split_sequence(valid['OutboundUtilzation (%)'].values,n_steps)\n",
    "test_x,test_y = split_sequence(test['OutboundUtilzation (%)'].values,n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkAnalyticsDataset(Dataset):\n",
    "    def __init__(self,feature,target):\n",
    "        self.feature = feature\n",
    "        self.target = target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.feature)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        item = self.feature[idx]\n",
    "        label = self.target[idx]\n",
    "        \n",
    "        return item, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeseriesCNN(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super(TimeseriesCNN,self).__init__()\n",
    "        self.conv1d = nn.Conv1d(3, 64, kernel_size=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc1 = nn.Linear(64, 50)\n",
    "        self.fc2 = nn.Linear(50, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1d(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.view(-1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = \"180\"\n",
    "\n",
    "if os.path.isfile(f'output/checkpoints/model{model_num}.pt'):\n",
    "    model = TimeseriesCNN()\n",
    "    model.load_state_dict(torch.load(f'output/checkpoints/model{model_num}.pt'))\n",
    "    model.to(device)\n",
    "else:\n",
    "    model = TimeseriesCNN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = NetworkAnalyticsDataset(train_x.reshape(train_x.shape[0],train_x.shape[1], 1), train_y)\n",
    "valid = NetworkAnalyticsDataset(valid_x.reshape(valid_x.shape[0],valid_x.shape[1], 1), valid_y)\n",
    "test = NetworkAnalyticsDataset(test_x.reshape(test_x.shape[0],test_x.shape[1], 1), test_y)\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=1, shuffle=False)\n",
    "valid_loader = DataLoader(valid, batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(test, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader : DataLoader):  \n",
    "    running_loss = .0\n",
    "    model.train()\n",
    "    \n",
    "    for idx, (inputs,labels) in enumerate(loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(inputs.float())\n",
    "        loss = criterion(preds,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss\n",
    "        \n",
    "    train_loss = running_loss/len(loader)\n",
    "    return train_loss.detach().cpu().numpy()\n",
    "    \n",
    "def validate(loader : DataLoader):\n",
    "    running_loss = .0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(inputs.float())\n",
    "            loss = criterion(preds,labels)\n",
    "            running_loss += loss\n",
    "            \n",
    "        valid_loss = running_loss/len(loader)\n",
    "        return valid_loss.detach().cpu().numpy()\n",
    "\n",
    "def test(model, loader : DataLoader):\n",
    "    running_loss = .0\n",
    "    model.eval()\n",
    "    predicted = []\n",
    "    actuals = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(inputs.float())\n",
    "            loss = criterion(preds,labels)\n",
    "            running_loss += loss\n",
    "            predicted.extend(preds.detach().cpu().numpy())\n",
    "            actuals.extend(labels.detach().cpu().numpy())\n",
    "            \n",
    "        test_loss = running_loss/len(loader)\n",
    "        return test_loss.detach().cpu().numpy(), predicted, actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absolute_error_statistics(original : np.array, predicted : np.array):\n",
    "    assert len(original) == len(predicted)\n",
    "    return np.absolute(original - predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1280.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.984262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.910873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.003975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.133748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.198843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.272672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>52.550213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  1280.000000\n",
       "mean      6.984262\n",
       "std       6.910873\n",
       "min       0.003975\n",
       "25%       3.133748\n",
       "50%       5.198843\n",
       "75%       8.272672\n",
       "max      52.550213"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 200\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "# for epoch in tqdm(range(epochs)):\n",
    "#     train_losses.append(train(train_loader))\n",
    "#     valid_losses.append(valid(valid_loader))\n",
    "#     gc.collect()\n",
    "#     if epoch % 20 == 0:\n",
    "#       torch.save(model.state_dict(), f\"output/checkpoints/model{epoch}.pt\")\n",
    "\n",
    "model180 = TimeseriesCNN()\n",
    "model180.load_state_dict(torch.load(f'output/checkpoints/model180.pt'))\n",
    "model180.to(device)\n",
    "\n",
    "\n",
    "test_error, predicted, actual = test(model180, test_loader)\n",
    "rest = absolute_error_statistics(np.array(actual), np.array(predicted))\n",
    "\n",
    "df = pd.DataFrame(rest)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1280.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.789247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.983126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.005478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.933885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.811438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.165678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>52.845879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  1280.000000\n",
       "mean      6.789247\n",
       "std       6.983126\n",
       "min       0.005478\n",
       "25%       2.933885\n",
       "50%       4.811438\n",
       "75%       8.165678\n",
       "max      52.845879"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model80 = TimeseriesCNN()\n",
    "model80.load_state_dict(torch.load(f'output/checkpoints/model80.pt'))\n",
    "model80.to(device)\n",
    "\n",
    "\n",
    "test_error, predicted, actual = test(model80, test_loader)\n",
    "rest = absolute_error_statistics(np.array(actual), np.array(predicted))\n",
    "\n",
    "df = pd.DataFrame(rest)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
